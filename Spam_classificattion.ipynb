{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam_classificattion.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNJI0JBRGwyXjFDjWPpsm2a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SAB-6/Spam-Classification/blob/master/Spam_classificattion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SANH6T7dyvEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktytfCW7y91g",
        "colab_type": "text"
      },
      "source": [
        "#  Table of Contents\n",
        "- [Step-1](#Project-Overview): Project objectives\n",
        "- [Step-2](#Load-Data-and-Explore-it): Understanding the dataset\n",
        "- [Step-3](#Data-Preprocessing) Data Preprocessing\n",
        "- [Step-4](#Train-model-and-make-prediction): Modeling\n",
        "- [Step-5](#Model-Evaluation): Model Evaluation\n",
        "- [Step-6](#Concluding-Remarks): Conclusion\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlx3fIHdUHka",
        "colab_type": "text"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixcpjr4Z1VCQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e9505eb9-f1ec-485d-c320-ac4b652422cf"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as matplot\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix, precision_recall_curve, roc_curve, roc_auc_score\n",
        "%matplotlib inline\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrJbzQ9X1c61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "outputId": "775d85fb-e5b3-4109-8312-2819720efe88"
      },
      "source": [
        "pip install tpot"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tpot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/0c/5f284a90e19f64aadb3b5c64b4abdd57471cb77dff7097c394be9f5b8d11/TPOT-0.11.4-py3-none-any.whl (82kB)\n",
            "\r\u001b[K     |████                            | 10kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 2.4MB/s \n",
            "\u001b[?25hCollecting stopit>=1.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/35/58/e8bb0b0fb05baf07bbac1450c447d753da65f9701f551dca79823ce15d50/stopit-1.1.2.tar.gz\n",
            "Collecting deap>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/eb/2bd0a32e3ce757fb26264765abbaedd6d4d3640d90219a513aeabd08ee2b/deap-1.3.1-cp36-cp36m-manylinux2010_x86_64.whl (157kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.4.1)\n",
            "Collecting update-checker>=0.16\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/c3/aaf8a162df8e8f9d321237c7c0e63aff95b42d19f1758f96606e3cabb245/update_checker-0.17-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.18.4)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (4.41.1)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.15.1)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.0.3)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from update-checker>=0.16->tpot) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->tpot) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->tpot) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.24.2->tpot) (1.12.0)\n",
            "Building wheels for collected packages: stopit\n",
            "  Building wheel for stopit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stopit: filename=stopit-1.1.2-cp36-none-any.whl size=11956 sha256=fff78134e9d9f63717a8b2303fd1ba9e64ad898dc59dc3515e518f46275408e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/85/2b/2580190404636bfc63e8de3dff629c03bb795021e1983a6cc7\n",
            "Successfully built stopit\n",
            "Installing collected packages: stopit, deap, update-checker, tpot\n",
            "Successfully installed deap-1.3.1 stopit-1.1.2 tpot-0.11.4 update-checker-0.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or-zuQZT5US-",
        "colab_type": "text"
      },
      "source": [
        "## Project Overview\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnMkR0J2REKk",
        "colab_type": "text"
      },
      "source": [
        "## Load Data and Explore it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhnrIQMMUPgC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "b6cb0adf-13c4-4f50-e5c6-c9b8316d392f"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-30 21:26:23--  https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 203415 (199K) [application/x-httpd-php]\n",
            "Saving to: ‘smsspamcollection.zip’\n",
            "\n",
            "smsspamcollection.z 100%[===================>] 198.65K   777KB/s    in 0.3s    \n",
            "\n",
            "2020-05-30 21:26:23 (777 KB/s) - ‘smsspamcollection.zip’ saved [203415/203415]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPB70plpWfXl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e25f2c4b-4cb1-4cef-a3e2-8ec62254f514"
      },
      "source": [
        "ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hidVlFfWWubd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "19bcb748-3c86-4a33-d6c9-01f17038527d"
      },
      "source": [
        "!unzip smsspamcollection.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  smsspamcollection.zip\n",
            "  inflating: SMSSpamCollection       \n",
            "  inflating: readme                  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLaOTzpIXaU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_table('SMSSpamCollection', sep ='\\t', names = ['label', 'sms_message'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHZfsl1VXjR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "4e72bd0a-5fb0-49e6-e3da-83d3c544022a"
      },
      "source": [
        "#check the first 10 samples \n",
        "df.head(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                        sms_message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
              "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
              "6   ham  Even my brother is not like to speak with me. ...\n",
              "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
              "8  spam  WINNER!! As a valued network customer you have...\n",
              "9  spam  Had your mobile 11 months or more? U R entitle..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAoVxwEkXn41",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "22592211-5133-4d1f-8276-4b1f062854d5"
      },
      "source": [
        "#check the last 10 samples\n",
        "df.tail(10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5562</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lor... Sony ericsson salesman... I ask shuh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5563</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ard 6 like dat lor.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5564</th>\n",
              "      <td>ham</td>\n",
              "      <td>Why don't you wait 'til at least wednesday to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5565</th>\n",
              "      <td>ham</td>\n",
              "      <td>Huh y lei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5566</th>\n",
              "      <td>spam</td>\n",
              "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     label                                        sms_message\n",
              "5562   ham  Ok lor... Sony ericsson salesman... I ask shuh...\n",
              "5563   ham                                Ard 6 like dat lor.\n",
              "5564   ham  Why don't you wait 'til at least wednesday to ...\n",
              "5565   ham                                       Huh y lei...\n",
              "5566  spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_luMkIJ8W-3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "9d501552-558b-4e5c-b55e-f7cef26b0fad"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   label        5572 non-null   object\n",
            " 1   sms_message  5572 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv4E3tHUYJxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df.isnull().sum().sort_values(ascending = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx5RRH-kY1yJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for i in df['sms_message']:\n",
        "#  print(len(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_fjY4DzREmu",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQDbWwqFawkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CountVectorizer?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCohYMPob5Ff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "0cb188e3-01b7-4bac-f528-bd4df7a0fa0d"
      },
      "source": [
        "#Turn target column (label) to numeric values\n",
        "create_numeric = lambda x: 1 if x == 'spam' else 0\n",
        "df['label'] = df.label.map(create_numeric)\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                        sms_message\n",
              "0      0  Go until jurong point, crazy.. Available only ...\n",
              "1      0                      Ok lar... Joking wif u oni...\n",
              "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      0  U dun say so early hor... U c already then say...\n",
              "4      0  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8CR8_jRfF8l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "f23ac471-4418-435e-9dca-29ab435c56b9"
      },
      "source": [
        "#(df.label.value_counts()/len(df)).hist()\n",
        "(df['label'].value_counts()/len(df)).plot(kind='bar', color = 'brown',figsize=(10, 6), stacked=False)\n",
        "plt.xlabel('Spam/Ham', fontsize=15)\n",
        "plt.ylabel('Percentage', fontsize=15)\n",
        "plt.title('Distribution of spam/ham messages', fontsize=15);"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIaLty3iecW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split data into training and test sets\n",
        "train_features, test_features, train_target, test_target = train_test_split(df['sms_message'],df['label'],\n",
        "                                                     random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAQMiHEj0TdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = stopwords.words(\"english\")\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9bqLQk1zlCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "    # normalize case and remove punctuation\n",
        "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
        "    \n",
        "    # tokenize text\n",
        "    tokens = word_tokenize(text)\n",
        "    \n",
        "    # lemmatize andremove stop words\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBHZOoOkZcBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate countvectoriozer and tfidf\n",
        "counter = CountVectorizer(stop_words= 'english')\n",
        "tfidf = TfidfTransformer()\n",
        "pipeline = Pipeline([('counter', counter), ('tfidf', tfidf)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiEIznc72zWN",
        "colab_type": "text"
      },
      "source": [
        "## Train model and make prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE2aVVhBb3yX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_train_features = pipeline.fit_transform(train_features)\n",
        "_test_features = pipeline.transform(test_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfzoPmNW27No",
        "colab_type": "text"
      },
      "source": [
        "## Build a base line model using logistic regression and make prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uintqXnK3CVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Instantiate logistic regression\n",
        "model_lr = LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89iuBjD53MwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "fc14c96b-5e11-495e-b5ff-48f386f37c2b"
      },
      "source": [
        "model_lr.fit(_train_features, train_target)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HDeDpsf39Xb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model_lr.predict(_test_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCdx9Go0ToFy",
        "colab_type": "text"
      },
      "source": [
        "## Model-Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TBoCfdG6JbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model(y_test, y_pred):\n",
        "    labels = np.unique(y_pred)\n",
        "    confusion_mat = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "    accuracy = (y_pred == y_test).mean()\n",
        "    precision = precision_score(y_test, y_pred, labels=labels, average = 'weighted')\n",
        "    recall = recall_score(y_test, y_pred, labels=labels, average = 'weighted')\n",
        "    f1 = f1_score(y_test, y_pred, labels=labels, average = 'weighted')\n",
        "\n",
        "    print(\"Labels:\", labels)\n",
        "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1_score:\", f1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4BxIyIX7agY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "d040ad05-a63f-4da4-8bb4-e5b611f1257d"
      },
      "source": [
        "evaluate_model(test_target, pred)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels: [0 1]\n",
            "Confusion Matrix:\n",
            " [[1207    0]\n",
            " [  45  141]]\n",
            "Accuracy: 0.9676956209619526\n",
            "Precision: 0.9688567208475055\n",
            "Recall: 0.9676956209619526\n",
            "F1_score: 0.9657684296265534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMwM5_tAWZ7g",
        "colab_type": "text"
      },
      "source": [
        "## Improving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-44yfe06WM5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create a column that ounts the number of words per message\n",
        "msg_length = lambda x: len(x.split())\n",
        "df['msg_length'] = df['sms_message'].apply(msg_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hnEXXk4uzuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a column to count the number of punctuation excluding comma and full stop\n",
        "from collections import Counter\n",
        "punct = [i for i in punctuation if i not in (',','.')]\n",
        "\n",
        "count_punct = lambda x: sum([1 for i in x if i in punct])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLmJ3H1VmWTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['punct']= df['sms_message'].map(count_punct)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3MtELH0vNL6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "64bc21e5-cd19-49c3-bf9b-02530b4967d7"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "      <th>msg_length</th>\n",
              "      <th>punct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>28</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                        sms_message  msg_length  punct\n",
              "0      0  Go until jurong point, crazy.. Available only ...          20      0\n",
              "1      0                      Ok lar... Joking wif u oni...           6      0\n",
              "2      1  Free entry in 2 a wkly comp to win FA Cup fina...          28      5\n",
              "3      0  U dun say so early hor... U c already then say...          11      0\n",
              "4      0  Nah I don't think he goes to usf, he lives aro...          13      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM6b9qGwarce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#counter = CountVectorizer(tokenizer = tokenize, stop_words= 'english', ngram_range=(1,2))\n",
        "#tfidf = TfidfTransformer()\n",
        "#pipeline = Pipeline([('counter', counter), ('tfidf', tfidf)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bal0sXTeZhx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df[df['label'] == 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3XFA1lRzKZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "    # normalize case and remove punctuation\n",
        "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
        "    \n",
        "    # tokenize text\n",
        "    tokens = word_tokenize(text)\n",
        "    \n",
        "    # lemmatize andremove stop words\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNNDUueM75DS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#numeric_features = ['msg_length','punct']\n",
        "#categorical_features = ['sms_message']\n",
        "\n",
        "#pipeline = make_pipeline(make_column_transformer(\n",
        "#    (categorical_features, make_pipeline(\n",
        "#       (CountVectorizer(tokenizer=tokenize)),\n",
        "#       (TfidfTransformer())\n",
        "#       )),\n",
        "#       (numeric_features, StandardScaler())),\n",
        "#       LogisticRegression())  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqPv78pyM1mp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numeric_features = ['msg_length','punct']\n",
        "categorical_features = ['sms_message']\n",
        "\n",
        "pipeline = Pipeline([\n",
        "                     ('transformer', make_column_transformer(\n",
        "                             (categorical_features, Pipeline([\n",
        "                            ('counter',CountVectorizer(tokenizer=tokenize)),\n",
        "                            ('tfidf',TfidfTransformer())\n",
        "                            ])),\n",
        "                        (numeric_features, StandardScaler())\n",
        "                        )),\n",
        "                      ('lr', LogisticRegression())\n",
        "                     ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L34wgej5Iog2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bcf4def8-576f-4dad-d725-85180199bfcf"
      },
      "source": [
        "pipeline.get_params()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lr': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                    warm_start=False),\n",
              " 'lr__C': 1.0,\n",
              " 'lr__class_weight': None,\n",
              " 'lr__dual': False,\n",
              " 'lr__fit_intercept': True,\n",
              " 'lr__intercept_scaling': 1,\n",
              " 'lr__l1_ratio': None,\n",
              " 'lr__max_iter': 100,\n",
              " 'lr__multi_class': 'auto',\n",
              " 'lr__n_jobs': None,\n",
              " 'lr__penalty': 'l2',\n",
              " 'lr__random_state': None,\n",
              " 'lr__solver': 'lbfgs',\n",
              " 'lr__tol': 0.0001,\n",
              " 'lr__verbose': 0,\n",
              " 'lr__warm_start': False,\n",
              " 'memory': None,\n",
              " 'steps': [('transformer',\n",
              "   ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
              "                     transformer_weights=None,\n",
              "                     transformers=[('list-1', ['sms_message'],\n",
              "                                    Pipeline(memory=None,\n",
              "                                             steps=[('counter',\n",
              "                                                     CountVectorizer(analyzer='word',\n",
              "                                                                     binary=False,\n",
              "                                                                     decode_error='strict',\n",
              "                                                                     dtype=<class 'numpy.int64'>,\n",
              "                                                                     encoding='utf-8',\n",
              "                                                                     input='content',\n",
              "                                                                     lowercase=True,\n",
              "                                                                     max_df=1.0,\n",
              "                                                                     max_features=None,\n",
              "                                                                     min_df=...\n",
              "                                                                     preprocessor=None,\n",
              "                                                                     stop_words=None,\n",
              "                                                                     strip_accents=None,\n",
              "                                                                     token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                                                     tokenizer=<function tokenize at 0x7fab76019510>,\n",
              "                                                                     vocabulary=None)),\n",
              "                                                    ('tfidf',\n",
              "                                                     TfidfTransformer(norm='l2',\n",
              "                                                                      smooth_idf=True,\n",
              "                                                                      sublinear_tf=False,\n",
              "                                                                      use_idf=True))],\n",
              "                                             verbose=False)),\n",
              "                                   ('list-2', ['msg_length', 'punct'],\n",
              "                                    StandardScaler(copy=True, with_mean=True,\n",
              "                                                   with_std=True))],\n",
              "                     verbose=False)),\n",
              "  ('lr',\n",
              "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                      intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                      multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                      random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                      warm_start=False))],\n",
              " 'transformer': ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
              "                   transformer_weights=None,\n",
              "                   transformers=[('list-1', ['sms_message'],\n",
              "                                  Pipeline(memory=None,\n",
              "                                           steps=[('counter',\n",
              "                                                   CountVectorizer(analyzer='word',\n",
              "                                                                   binary=False,\n",
              "                                                                   decode_error='strict',\n",
              "                                                                   dtype=<class 'numpy.int64'>,\n",
              "                                                                   encoding='utf-8',\n",
              "                                                                   input='content',\n",
              "                                                                   lowercase=True,\n",
              "                                                                   max_df=1.0,\n",
              "                                                                   max_features=None,\n",
              "                                                                   min_df=...\n",
              "                                                                   preprocessor=None,\n",
              "                                                                   stop_words=None,\n",
              "                                                                   strip_accents=None,\n",
              "                                                                   token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                                                   tokenizer=<function tokenize at 0x7fab76019510>,\n",
              "                                                                   vocabulary=None)),\n",
              "                                                  ('tfidf',\n",
              "                                                   TfidfTransformer(norm='l2',\n",
              "                                                                    smooth_idf=True,\n",
              "                                                                    sublinear_tf=False,\n",
              "                                                                    use_idf=True))],\n",
              "                                           verbose=False)),\n",
              "                                 ('list-2', ['msg_length', 'punct'],\n",
              "                                  StandardScaler(copy=True, with_mean=True,\n",
              "                                                 with_std=True))],\n",
              "                   verbose=False),\n",
              " 'transformer__list-1': ['sms_message'],\n",
              " 'transformer__list-2': ['msg_length', 'punct'],\n",
              " 'transformer__n_jobs': None,\n",
              " 'transformer__remainder': 'drop',\n",
              " 'transformer__sparse_threshold': 0.3,\n",
              " 'transformer__transformer_weights': None,\n",
              " 'transformer__transformers': [('list-1',\n",
              "   ['sms_message'],\n",
              "   Pipeline(memory=None,\n",
              "            steps=[('counter',\n",
              "                    CountVectorizer(analyzer='word', binary=False,\n",
              "                                    decode_error='strict',\n",
              "                                    dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                    input='content', lowercase=True, max_df=1.0,\n",
              "                                    max_features=None, min_df=1,\n",
              "                                    ngram_range=(1, 1), preprocessor=None,\n",
              "                                    stop_words=None, strip_accents=None,\n",
              "                                    token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                    tokenizer=<function tokenize at 0x7fab76019510>,\n",
              "                                    vocabulary=None)),\n",
              "                   ('tfidf',\n",
              "                    TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                     sublinear_tf=False, use_idf=True))],\n",
              "            verbose=False)),\n",
              "  ('list-2',\n",
              "   ['msg_length', 'punct'],\n",
              "   StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
              " 'transformer__verbose': False,\n",
              " 'verbose': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFTLdu_VJkn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid ={'lr_C' = [0.5,1.0,1.0],\n",
        "             'lr__penalty' =['l1','l2']\n",
        "             'columntransformer'\n",
        "             }\n",
        "\n",
        "param_grid = {\n",
        "    'columntransformer__pipeline__simpleimputer__strategy': ['mean', 'median'],\n",
        "    'logisticregression__C': [0.1, 1.0, 1.0],\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt77Blhs4htd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline = Pipeline([\n",
        "    ('features', FeatureUnion([\n",
        "\n",
        "        ('text_pipeline', Pipeline([\n",
        "            ('vect', CountVectorizer(tokenizer=tokenize)),\n",
        "            ('tfidf', TfidfTransformer())\n",
        "        ])),\n",
        "\n",
        "        ('starting_verb', StartingVerbExtractor())\n",
        "    ])),\n",
        "\n",
        "    ('lr', LogisticRegression())\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXRXQ7UFy-3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline = Pipeline([\n",
        "    ('features', FeatureUnion([\n",
        "\n",
        "        ('text_pipeline', Pipeline([\n",
        "            ('vect', CountVectorizer(tokenizer=tokenize)),\n",
        "            ('tfidf', TfidfTransformer())\n",
        "        ])),\n",
        "\n",
        "        ('starting_verb', StartingVerbExtractor())\n",
        "    ])),\n",
        "\n",
        "    ('clf', RandomForestClassifier())\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_J_tyrE4b8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtnLzMM5xHJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_pipeline():\n",
        "    pipeline = Pipeline([\n",
        "                        ('feature',FeatureUnion([\n",
        "                            \n",
        "                            ('nlp_pipeline', Pipeline([\n",
        "                                ('count',CountVectorizer(tokenizer=tokenize)),\n",
        "                                  ('tfidf',TfidfTransformer())\n",
        "                            ])),\n",
        "                                        \n",
        "                            ('strvb', StartingVerbExtractor())\n",
        "                            ])),\n",
        "                         \n",
        "                         ('clf', RandomForestClassifier())])\n",
        "    \n",
        "    \n",
        "\n",
        "    return pipeline\n",
        "\n",
        "def load_data(engineer_data = True):\n",
        "    !wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
        "    df = pd.read_csv('corporate_messaging.csv', encoding='latin-1')\n",
        "    df = df[(df[\"category:confidence\"] == 1) & (df['category'] != 'Exclude')]\n",
        "    X = df.text.values\n",
        "    y = df.category.values\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    detected_urls = re.findall(url_regex, text)\n",
        "    for url in detected_urls:\n",
        "        text = text.replace(url, \"urlplaceholder\")\n",
        "\n",
        "    tokens = word_tokenize(text)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    clean_tokens = []\n",
        "    for tok in tokens:\n",
        "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
        "        clean_tokens.append(clean_tok)\n",
        "\n",
        "    return clean_tokens\n",
        "\n",
        "\n",
        "def display_results(y_test, y_pred):\n",
        "    labels = np.unique(y_pred)\n",
        "    confusion_mat = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "    accuracy = (y_pred == y_test).mean()\n",
        "\n",
        "    print(\"Labels:\", labels)\n",
        "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "def main():\n",
        "    X, y = load_data()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "    model = model_pipeline()\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    display_results(y_test, y_pred)\n",
        "\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewtN4Jr6Tvuw",
        "colab_type": "text"
      },
      "source": [
        "## Concluding Remarks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFQy8pRh5TdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvDiWzfj1kQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}